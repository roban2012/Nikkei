<!DOCTYPE html>
<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.

	God gives, but man must open his hands. 
	You can contact Retter2012.com Team through jobnet@188.com

-->


<html>
<head>
	
	<meta http-equiv="Content-Type" content="text/html; charset=gb2312"/>
	<!-- Try this way:  <meta http-equiv="Content-Type" content="text/html" charset="gb2312"/> -->
	<meta name="format-detection" content="telephone=no"/>
	<meta name="viewport" content="user-scalable=no, initial-scale=1, maximum-scale=1, minimum-scale=1, width=device-width, height=device-height, target-densitydpi=device-dpi" />
	<title>Read Link Text</title>
	<meta name="Author" content="Roban">
	<meta name="Keywords" content="Retter2012.com">
	

</head>

<body bgcolor= "white" background= "" text="black" link="silver" alink="navy" vlink="red">
	<center>
	<br><a href= "home.html">返回主页</a><br>
	<font size=7>
	最新的机器翻译
	</font>	
	</center>

	<font size=5>
	<br><br>

机器翻译的最新进展与瓶颈所在<br><br>

时间:2012-02-09 10:25 来源:中国网  <br><br>


你想过和异国人说话不需要再有翻译，只需随身携带一个轻巧的数码机器吗？目前来看这仍是奢望。不过，或许某一天，我们终于可以不再学习头疼的外语就能实现和外国人的无缝交流。<br><br>

 

 机器翻译是一个充满挑战的研究领域，正因为难度很大，它被列为21世纪世界十大科技难题之首。一路走来，机译经历了艰难而曲折的发展历程，既有成功和兴奋，也有挫折和困惑。<br><br>
 

 然而，需求永远走在应用的前方。由于近年来全球化进程的加速以及国际交流的日趋频繁，人们对于翻译的需求空前增长。而互联网的普遍应用则使在线翻译成了当今机译的重头戏。<br><br>
 

 在这一领域，竞争正变得空前激烈。如今功能较强、方便易用的在线翻译工具有谷歌翻译、必应翻译、脸谱翻译、宝贝鱼翻译、巴比伦翻译等，其中后起之秀的谷歌翻译最具特色，同时最具代表性。<br><br>
 

 谷歌翻译目前可提供63种主要语言之间的实时翻译；它可以提供所支持的任意两种语言之间的互译，包括字词、句子、文本和网页翻译。另外它还可以 帮助用户阅读搜索结果、网页、电子邮件、YouTube视频字幕以及其它信息，用户甚至还能在Gmail内进行实时的多语言对话。<br><br>
 

 谷歌翻译主要是采用统计翻译模型，往计算器内输入大量的文字文本，包括源语言的文本，以及对应目标语言人工翻译的文本，通过海量统计数据来提高翻译精确度。<br><br>
 

 之所以采用统计翻译模型，一个重要原因是，谷歌翻译采用了云计算架构。该架构拥有谷歌研发的分布式计算系统（MapReduce）和分布式存储系统（BigTable）；而这两个系统很有创造性，而且有极大的扩展性，使得谷歌在系统吞吐量上有很大的竞争力。
 <br><br>

 机译更激动人心的应用，在于日常对话中的实时翻译。这一领域同样是谷歌领先；它拥有较强的语音识别技术，可以通过声音实现自动检索，再将语音识别和机译结合在一起。
 <br><br>

 2011年11月，谷歌最新推出了一款手机翻译软件；该软件支持包括汉语普通话在内的14个语种。对着谷歌Android智能手机讲话的用户，几乎能实时听到他们的源语言被翻译成目标语言；而通话对方的语言也会被翻译成该用户的母语。
 
<br><br>
 谷歌董事长埃里克施密特称，这种手机翻译服务将会得到极大改善，甚至可能进行“同声传译”；其前景是令人乐观的。
 
<br><br>
 谷歌的首席科学家阿施斯维努戈帕尔称，谷歌的最终目的是研发出能够翻译全球至少10亿人所说的300种语言的手机软件。
 <br><br>

 除了传统的翻译思路，一种被称为解a外语的新方法也小荷露出尖尖角。
 
<br><br>
 这项由南加州大学的科学家们提出的全新机译方法把英语视为一种初始语言，而需要翻译的外语类似一种加密后的高级文字，通过译码破译，把外语“破解”，变成英语。
 
<br><br>
 不过，现实是骨感的。目前，这种翻译方法只能翻译一些短句或电影字幕，尚未运用到长句或片段翻译中，但它却给机译研究打开了一条新的思路，且可 以运用到任何一种语言中。科学家们称，因为不需要任何既有的文本为基础，这种翻译方法今后甚至可以对“海豚音”或“外星人语言”进行破译。
 <br><br>

   事实上，不论哪种方法，影响机译发展的最大因素在于译文的质量。就已有的成就来看，机译的质量离终极目标仍相差甚远。
 <br><br>

 中国数学家、语言学家周海中曾在论文《机器翻译五十年》中指出：要提高机译的质量，首先要解决的是语言本身问题而不是程序设计问题；单靠若干程序来做机译系统，肯定是无法提高机译质量的。
 
<br><br>
 同时，他还指出：在人类尚未明了“人脑是如何进行语言的模糊识别和逻辑判断”的情况下，机译要想达到“信、达、雅”的程度是不可能的。这也是制约机译质量提高的一大瓶颈。
 <br><br>

 值得一提的是，美国发明家、未来学家雷科兹威尔最近在接受《赫芬顿邮报》采访时预言，到2029年机译的质量将达到人工翻译的水平。对于这一论断，学术界还存在很多争议。
 <br><br>

 不论怎样，目前是人们对机译最为看好的时期，这种关注是建立在一个客观认识和理性思考的基础上的。我们也有理由相信：在计算器专家、语言学家、心理学家、逻辑学家和数学家的共同努力下，机译的瓶颈问题将会得以解决。
<br><br>

	您也可以<a href= "http://www.retter2012.com" title="点击进入"> 先下载一个</a>应用程序（App），有空再慢慢看。<br><br>
语音机器人的语言困局
<br><br>
时间:2012-09-17 环球科学（huanqiukexue.com）  
<br><br>

教机器说话，是我们怀揣数十年的一个梦想。但首先要弄明白，有关语言的知识，我们究竟是如何获得的。
世界上首台会交谈的机器人Sulla是聊天高手，能讲整整四种语言，其功夫之纯熟，令每一位到她所诞生的实验室参观的访客难以相信她竟不是真人。
<br><br>
 其实Sulla也不是真正的机器人，而是捷克剧作家卡雷尔・恰佩克（Carel Capek）1921年撰写的科幻剧《罗素姆的万能机器人》（Rossum’s Universal Robots，缩写为R.U.R）中的一位角色。该剧首次引入了“机器人”（robot）这个专业词汇。这是会交谈的机器人的首次亮相，此后它们似乎就满世界探头探脑，跃跃欲试，而不仅仅是出现在科幻小说中。 
<br><br>
 几乎是现代计算机刚一发明出来，研究人员就开始考虑如何为电脑编程，以使其能够运用语言。1950年，计算机科学的奠基人之一阿兰・M・图灵（Alan M. Turing）预言，到20世纪末时，机器人将能够非常熟练地运用英语，以至于出现人机难辨的局面（后来人们就把判断机器是否达到这一水平的测试称为“图灵测试”）。4年后，美国乔治敦大学与IBM公司的科学家联手推出了701翻译机，成功地以每秒两行半的速度，将60个俄文句子翻成了英文，致使构想出该翻译机所用方法的研究人员利昂・多斯特尔（Leon Dostert）自信满满地宣称，流利的电子翻译机“顶多五年，说不定三年”就会问世了。
<br><br>
 岂料，直到今天我们还在等待。经历了一波又一波乐观的预言，紧跟着的是一次又一次凄凉的挫折这样的轮回之后，不得不承认，完全够格的交谈机器人现在似乎同20世纪中期其他那些异想天开的预言（诸如建设海底城市、向火星移民等）一样离我们有十万八千里之遥。要说有什么不同的话，那就是现在我们追求交谈机器人的欲望更加强烈，因为我们迫切想抛掉键盘这个同数码工具和日益袖珍的电子产品打交道的界面。
<br><br>
 近年来，人工语音研究的成果有喜有忧，喜的是若干机器理解语言的能力达到相当水平，可以干点有用的事了（例如谷歌翻译以及你致电客服时听到的自动语音回复），忧的是我们仍然要面对此项技术的种种短板，以及它容易发生严重故障的事实（例子还是谷歌翻译以及你致电客服时听到的自动语音回复）。还有些项目则尝试通过互联网上民间参与的众包方式来克服这些不足，这样我们兴许会更加了解我们是如何选择用词的。
<br><br>
 但技术并不是唯一的问题，甚至也不是最大的问题：实践证明，解读语言的奥秘，其难度之大远超任何人的想象。我们能够搞定诸如从一个单词的多种意义中，选择正合要求的那个意义之类的任务，这种本领其实是人类数百万年进化的产物。我们做这些事时不必知道是如何做的，更不必知道如何把这种本领传授给人造的机器。事实上，当科学家在尝试概括地表述语法，并仔细梳理出类似词汇之间的微妙差别时，他们就逐渐明白语言的意义往往是难以捉摸的，而语言的结构即使对于已经熟练掌握了语言的人类来说也是一个难解之谜。
<br><br>
 

突破旧框框
<br><br>


语境提醒 心中有数
<br><br>
研究表明，在遇到“bank”之类多义词时，人们可以从上下文中获取线索，很快锁定正合需要的那个意义：“swim”（游泳）提示河岸，而“check”（支票）则提示银行。

 <br><br>

 打造交谈机器人的最初尝试简单得令人难以置信――用语法规则对机器人进行设置就大功告成了。这是IBM公司对701翻译机所采用的招数。由于冷战时期，苏联一举一动都为美国所关注，因此701在首次公开展露功夫时接受的任务就是把俄文翻成英文。1954年，介绍此项目的宣传资料解释了701如何处理两种语言间的差异（如词序的不同）。例如，俄文的“gyeneral mayor”（少将）翻成英文是“major general”，这样，每当翻译机遇到俄文中的mayor这个词时，它便检查其前面的单词。如果正好是gyeneral，它在翻成英文时就把两个词的顺序倒过来。
<br><br>
 这样简单的系统居然也能玩翻译，其原因之一在于，701只认得250个俄文单词，因此识别其数据库中的每一个“形容词+名词”组合不算什么麻烦事。但许多语言都有数十万个单词，而英语的单词可能超过一百万。假设英语中一半的单词具有多种意义应该是说得过去的，不过那样一来，程序员就必须考虑5 000亿种单词组合。如果把这些组合都写入程序，以每秒写一个组合计算，程序员要花1.6万年才能写完。
<br><br>
 不巧的是，短语gyeneral mayor在俄语中其实是个异类。一般说来俄语中的此类词序与英语相同，而与西班牙语这样的语言相反（西班牙语中形容词通常跟在名词后面）。对词汇量较大的翻译机来说，一个显而易见的解决方案是为它设置诸如“英语和俄语中的形容词在名词前面，而西班牙语中的形容词在名词后面”之类的规则，并附上一张例外情况的列表。这一招不仅可以大大减少规则的数量，同时也让系统能够搞定新的单词。但问题在于，解释例外的规则本身可能又有例外。科学家尚未发现一套可以完美解读英语、俄语或其他任何一种语言的抽象规则，尽管语法教科书的出版商不愿意承认这一点。
<br><br>
 但这些系统之所以脆弱，不仅是因为语法规则不可能做到尽善尽美，而且是因为像领悟单个词汇的意义这样看似简单的任务，其实都暗含着复杂的玄机。

 <br><br>

多义词
<br><br>
交谈机器人（以及打造交谈机器人的工程师）首先遇到的向题之一是，我们日常谈话中所用到的词，有许多属于同音异义字，即有多种意义。比如，“bank”可指银行（“John cashed a check at the bank”，约翰在银行兑换了一张支票），也可指河岸（“John swam to the nearest bank”，约翰向最近的岸边游去）。
<br><br>
 人们在遇到这类句子时很快就会锁定正确的意义。美国加利福尼亚大学圣迭戈分校的心理语言学家西玛・范佩滕（Cyma van Petten）、马塔・库塔斯（Marta Kutas）在1987年的一篇著名论文中，阐述了“词汇启动”（lexical priming，指的是人们遇见某个单词时，该单词即会提示人们注意与语境相关的其他单词的意义），论证了人的这种能力。两位语言学家发现，当人们看到一个“bank”之类的多义词后刚半秒多点，他们就注意到提示语境的其他关键词汇了（如“money”和“river”）。
<br><br>
 对于某些特殊群体，这些功能会有异常。2002年，美国塔夫斯大学的塔蒂亚纳・斯蒂尼科娃（Tatiana Sitnikova）和同事发现，精神分裂症患者无法排除一个多义词与前后语境搭不上界的意义。比如，他们看到“bat”（有球拍与蝙蝠两种意义）之后一秒多钟，仍有“本垒打”和“吸血蝠”这两个意思在他们的脑袋里面转。
<br><br>
 不过，上述研究仅能告诉我们，大多数人可以根据语境，很快搞定同音异义的状况。但对设计交谈机器人的工程师来说，问题在于人们并不知道自己是如何做到这一点的。有一种理论认为，我们利用了多义词前后的词。例如，对银行的论述中常有“支票”、“兑现金”等字眼，而对河岸的描述中常有“游泳”、“水”等字眼。或许，我们就是直接由此领悟到，某些词提示了“bank”的一种意义，而另一些词则提示了“bank”的另一种意义。
<br><br>
 比同音异义字更难摆平的是它的“同党”――多义词。多义词与同音异义词一样有多种意义，但其各种意义是密切相关的。比如在“Jane Austen wrote many books”（简・奥斯汀写过许多作品）与“I read some Jane Austen this afternoon.”（今天下午我读了简・奥斯汀写的一些作品）两句中，“Jane Austen”在头一句里指的是作者，而第二句中则指她的作品。其实，不仅是所有作者的名字，所有传媒名称都存在多义现象。“Rupert Murdoch has bought the Wall Street Journal”是指这位报业巨头买下了该报社，把默多克换成我，“I have bought the Wall Street Journal”，则是说我买了一期《华尔街日报》。
<br><br>
 对多义词，语境显然也非常重要，但这类区别相当微妙，很难界定。“bank”的两种意义很少出现在同一个句子中，但“Jane Austen”却往往与“Pride and Prejudice”（傲慢与偏见）出现在同一个句子中，有时指作者，有时则指其作品，因此，只依靠前后的字词来澄清歧义并不总是行得通的。我们仍然未完全弄明白人们如何找出正确的意义。
<br><br>
 诸如“bank” 和“Jane Austen” 之类的词汇之所以造成麻烦，就是因为它们有几种含义。那么，可怜的机器人如果必须面对具有几乎无穷多种意义的代词，其处境岂不是更加值得同情？在“I wrote Pride and Prejudice”（我写了《傲慢与偏见》一书）这个句子中，如果是简・奥斯汀自己在讲这句话，那么代词“I” 就是指她。如果讲话的是扮演简・奥斯汀的演员[如出演电影《珍爱来临》（Becoming Jane）中简・奥斯汀一角的安妮・海瑟薇]，那么“I” 就不是指讲话的人，而是指她所演的人。这类情况无法用一条简单的规则来概括。第三人称代词则更为棘手。在“She wrote Pride and Prejudice”（她写了《傲慢与偏见》一书）这个句子中，不论是谁在讲这句话，代词“she” 都可以指任何一位女性。机器人不可能撇开这些歧义不管而自顾自地翻译下去，因为如果不知道这个句子讲的是谁，那这句话就几乎没有什么意义。<br><br>

 要想搞定这个代词瓶颈，最出名的解决方案或许要算所谓中心理论（Centering Theory）。该理论是哈佛大学计算机科学家巴巴拉・格罗斯（Barbara Grosz）及宾夕法尼亚大学计算机科学家阿拉文德・K・乔斯（Aravind K. Joshi）和哲学家斯科特・温斯坦（Scott Weinstein）在上世纪八九十年代提出并加以完善的，该理论全面阐释了在一段比较长的讲话中，各个句子是如何和谐地对接的。中心理论认为，人们通常用“she”之类的代词来指代前一句的中心（即最主要的角色），也就是这句话的主语。这种说法可以解释为何在“Jane Austen was an author. She wrote Pride and Prejudice”（简・奥斯汀是一位作家。她写了《傲慢与偏见》一书）等句子中，人们一般以“she”指代简・奥斯汀。
<br><br>
 遗憾的是，对机器人而言，事情并不总是如此简单。心理语言学家詹妮弗・阿诺德（Jennifer Arnold）在1998年的论文中估计，作主语的人称代词中，仅有约64%指代前面的主语。此外，多项研究――最早可追溯到约翰斯・霍普金斯大学的语言学家凯瑟琳・加维（Catherine Garvey）和神经科学家阿方索・卡拉马扎（Alfonso Caramazza）在1974年的一篇开创性论文――已经揭示，人们在解读代词的指代时，语境线索之微妙复杂堪称令人抓狂。例如，我与哈佛大学心理学家杰西・斯内德克（Jesse Snedeker）在一篇论文中报道了这样一个结果：对于“Sally frightened Mary because she is strange”（萨丽吓着了玛丽，因为她是陌生人）一句，绝大多数人认为代词“she”是指萨丽，但对于“Sally feared Mary because she is strange”（萨丽害怕玛丽，因为她是陌生人）一句，大多数人认为代词是指玛丽。人们为何会如此认定，无人知晓，反正大家很快就会作出这样的判断。
<br><br>
 2007年，荷兰阿姆斯特丹大学心理语言学家约斯・范伯克姆（Jos van Berkum）和同事让受试者看一些句子，同时观察他们的脑电波变化情况。这些句子有的符合人们的预期模式，如“Sally frightened John because she is strange”（萨丽吓着了约翰，因为她是陌生人），有的则与一般预期冲突，如“Sally frightened John because he is strange”（萨丽吓着了约翰，因为他是陌生人）。脑电图揭示，当代词的使用与句子语境不般配时（比如在上句中用了“他”，而不是“她”），脑波中有迹象表明，大脑对此又下了一番功夫进行处理。

 <br><br>

统计模式
<br><br>
翻译天地 大有文章
<br><br>
科学家为其创建的语言机输入巨量的文本，称为语料库。谷歌翻译就是靠已经翻译成多种语言的大量联合国文件充实起来的，它有助于澄清歧义。

 <br><br>

 由于单词意义具有千变万化的微妙差别，科学家需要找到恰当的方法来帮助机器人改进预测方式。许多学者求助于语言的统计处理，就是把不计其数的素材塞进他们的计算机中，然后进行统计分析。首先，他们把名为语料库的巨量文本集合――有时超过十亿单词――灌入机器中。然后，机器把这些文本分解成由n个连续单词构成的无数段，每段称作一个n元。机器对它吞进的所有n元进行分析后，就知道了哪些单词一般会同什么单词搭配。例如，机器人最终会弄清楚，“tall man”（高个子男人）这个短语在英语中相当常见（在网上搜索，会出现大量相关词条），而“man tall”则相对少见。类似地，机器也可以学到如下知识：如果句子中的“bank”前面有“swam”，那么它的意思多半是“河岸”。701翻译机实际上就是在对n元（更确切地说是由两个单词构成的二元短语）进行分析。
<br><br>
 统计模式的优点在于，程序员不需要制定诸如“‘general’要在‘major’前面”之类的具体规则，甚至也不需要制定“形容词要在名词前面”之类的抽象规则，统计系统只需要弄清哪些词在哪些词的前面。更复杂的方案则可能也会跟踪词类信息，以便让语言机器知道，当“check”用作名词而非动词时，它很可能与“银行”有关。
<br><br>
 研究也表明，统计学习――即通过语境来识别语言模式――可能有助于人们学习语言，因而这种方法格外受机器人工程师的青睐。美国罗切斯特大学心理学家詹尼・萨福兰（Jenny Saffran）、理查德・阿斯林（Richard Aslin）和艾丽莎・纽波特（Elissa Newport）1996年的一项研究显示，甚至连8个月大的婴儿也能领会三元概率，即三联词汇或音节中各单词或音节依次出现的可能性。研究人员让婴儿倾听一串无意义的音节，如bidakupadotigolabi。其中bidaku、padoti和golabi这几个三元词出现得非常频繁，而其他三元词（包括dakupa）的出现次数少得多。听了这些无意义的音节串两分钟之后，婴儿们就能区分常见和不常见的三元词（对于不常见的三元词他们会听得更久一些，就像是听到新的音节一样）。几位科学家把这种能力解读为，儿童可能是通过这一方式来分清他们听到的单词。类似地，2010年，美国圣路易斯大学心理学家克里斯托弗・康维（Christopher Conway）领导的一个团队发现，擅长统计学习的人也擅长于在嘈杂的环境下听懂谈话。
<br><br>
 虽然n元机器并非科学家正在尝试的唯一一种语言系统，但工程师对这类系统情有独钟，因为现在海量语料库一抓一大把，要弄到一个易如反掌。比如，谷歌就发布了一个网上语料库，单词量在万亿以上。但为了让语料库分清单词的意义和代词指代的种种复杂微妙之处，必须对每个句子加以标注，也就是标出每个单词的意思或词类，但现在大多数基本语料库并未做这项工作。对词义作了标注的最大语料库是SemCor（SemCor是semantic correlation即语义关联的缩写），是由普林斯顿大学创建，包含36万个单词。从标注这些单词所需的工作量来看，这是一个非常大的语料库，但按语音工程师的需要来衡量，它又太小了。
<br><br>
 看看谷歌推出的两种n元系统，我们就可以领略到n元机由此而来的长处与软肋。其中一个系统是谷歌翻译。谷歌向这个统计型翻译工具灌进了大量已经翻译成多种语言的文本（谷歌翻译最初的资料库的内容，主要就是用多种语言发布的联合国文件）。由于某种语言中的一个同音多义字，在另一种语言中通常要用两个词来表示[比如英语中‘bank’的两个意思，在西班牙语中就分别用orilla（岸边）和banco（银行）来表示]，因此用于训练统计型翻译机器人的双语语料库就可以充当有词义标注的语料库。翻译机可以学会区分英语中含有“bank”，而西班牙语中含有“orilla”的句子（往往还有“swim”这个词），以及英语中含有“bank”，而西班牙语中含有“banco”的句子（往往还有“cashed”和“check”之类词汇）。
<br><br>
 谷歌最近推出了一款名为谷歌抄写（Google Scribe）的工具，其实就是一种n元机，用于句子的书写――它可以在你打字时实时提示下一个要输入的单词。比如当你输入“major”时，机器便帮你联想到“role”、“cities”、“and”、“role in”、“problem”、“histocompatibility complex”、“league”等。这些全是与major搭配的常见词汇[连“major histocompatibility complex”（主要组织相容性复合体，生物学上的专业词汇）都属于常见的组合，在谷歌中的搜索次数超过百万次]。
<br><br>
 联想建议是如此的多，凸显了现今n元机的一个重大局限性。由于n元机跟踪的上下文仅有几个单词，因此，如果相关单词隔得太远，机器往往会乱了方寸。比如输入“He swam to the bank”（他游向岸边），谷歌翻译会返回正确的西班牙语译文“él nadó hasta la orilla”，但若输入“He swam to the nearest bank”（他游向最近的岸边），则谷歌翻译会给你“él nadó hasta el banco más cercano”，意为“He swam to the nearest fnancial institution”（他游向最近的银行）。双语语料库在应对多义词和代词时也显得很不给力。某种语言中的许多多义词在其他语言中也是多义词。
<br><br>
 同样，谷歌抄写和其他简单的n元机既无法搞定新词，也不能生成有用的句子。即便是幼儿也会用新词造句，但你在谷歌翻译中输入新造的词“wug”后，它不会给你任何提示。而且，由于它只能领会很短的短语的统计规律，因此对于由它生成的句子，如果逐个单词来看，你知道每个单词是什么意思，但全部连起来就成了不知所云的东拉西扯。例如，向谷歌抄写输入“Google”，然后依次在每个单词之后输入它提示的首个联想词，则最终得到这样一句：“Google Scholar search results on terms that are relevant to the topic of the Large Hadron Collider at the European level and the other is a more detailed description of the invention.”这样的n元系统生成的句子，其句首与句尾多半是南辕北辙，很难对得上号。
<br><br>
求助网友

<br><br>

改进n元机最简单的招数之一，就是让它们使用更长的句子。但说来容易做起来难。假设某种语言仅有一万个单词。为了把所有潜在的三元短语一网打尽，单词机得学习一万的三次方即万亿种组合。而要把每一个六词组合都收罗进来（其实，对这种任务来说六个单词仍然不够长），则得存储1024种组合，相当于十万亿EB的信息（一EB为十亿GB）。想想看，截至2009年，全球所有数字信息据估计也不过500EB而已。
<br><br>
 不过，即使有了巨量的词义标注语料库作靠山，聪明的“机器人学生”仍然还得学一些实用的功夫，说起话来才比较靠谱。以色列希伯来大学的哲学家耶霍舒亚・巴尔－希勒尔（Yehoshua Bar-Hillel）在1960年的一篇经典论文中指出，单靠上下文，永远也无法解释为什么人人皆知“the box was in the pen”（箱子放在栅栏里）中的“pen” 必定是指一块围起来的场地而非钢笔。人们作出这样的推断，并非根据上下文，而是根据他们的常识――箱子不可能塞进钢笔里。
<br><br>
 为了让机器人在填补数据空白的同时，也在现实的江湖里多磨练磨练，近来若干个依托网络的项目尝试求助于广大网友的力量。美国卡内基・梅隆大学以安东尼・托马西克（Anthony Tomasic）为首的一批计算机科学家将推出一个名为Jinx的网上游戏。游戏中，系统将向两位玩家显示包含在一个句子中的某个单词（例如“John cashed a check at the BANK” 中的“BANK”），并要求玩家尽快输入相关词汇。如果两个玩家输入同样的词，则可赢得点数。研究人员可以利用他们的判断来标注多义词的意义（尤其当玩家意见一致时），从而打造一个比SemCor更大的语料库。
<br><br>
 我自己做的网站“代词侦探”（Pronoun Sleuth ，网址gameswithwords.org/PronounSleuth）则是让自愿参加的网友看一些包含代词的句子，并判断其中代词是指哪位（例如“Sally went to the store with Mary. She bought ice cream.”（萨丽同玛丽一起去商店。她买了冰淇淋）。对于某些句子，参与者的判断相当一致，但对于另外一些句子，意见则不那么统一。
<br><br>
 我们发现，要把一类句子同另一类句子区分开来，需要30～40位网友的意见。最终有500多位参与者对几个句子作出了判断。不久前，我和斯内德克递交的一份论文，收集了针对一千个句子的数据――机器人要想理顺代词用法的微妙差别，一千个句子仍嫌太少，但这已经是现有的针对这类句子的最大数据库了。
<br><br>
 2008年，英国埃塞克斯大学的计算机科学家创建了“短语侦探”（anawiki.essex.ac.uk/phrasedetectives），采取了一个较为传统的思路。“短语侦探”会向参与者出示一本书或一篇文章中的一段，当参与者遇到一个代词时，便须找出它指代的是哪个词。“短语侦探”也会询问参与者对其他指代性短语的判断。例如，实验人员想知道参与者是否会认出“Jane Austen wrote Pride and Prejudice. The book was very popular”（简・奥斯汀写了《傲慢与偏见》。该书非常受欢迎）这段话中，“the book”是指“Pride and Prejudice”。迄今，“短语侦探”的参与者们已经完成了对317份文档的判断。把这类项目所产生的数据综合起来，我们就能建立并检验相关理论，并在理论的指引下，最终打造出会使用代词的机器人。
<br><br>
 不过，什么时候能实现这个目标仍是一个有争议的问题，而且我们的预期也可能同以往一样完全不靠谱。虽然谷歌公司机器翻译团队的老大弗朗兹・约瑟夫・奥克（Franz Joseph Och）对前路上的障碍心知肚明，但他不久前在接受《洛杉矶时报》采访时仍宣称，具有《星际旅行》中万能翻译机那种神奇功力（即讲即翻式的同步传译）的语音机器人有可能在“不太遥远的未来”诞生。不过，打造会说话的机器人的前提是深刻领悟语言的奥秘，而事实可能会证明，语言之难于捉摸，绝不逊于《星际旅行》中其他任何神奇的东西。
<br><br>
 本文来自《环球科学》2012年第6期，转载请注明出处。<br><br>
机器人宝宝在人的教导下首次“呀呀学语”<br><br>

时间:2012-07-12  环球科学（huanqiukexue.com）  
<br><br>

通过模仿人类小孩学习语言的过程，计算机学家首次教会机器人说出实际的单词。

<br><br>

一开始的时候，机器人宝宝只是发出一些语无伦次的噪音，但是几分钟后，它突然发出了完整清晰的单词：“红色”，接着另一个单词：“盒子”。这样只是通过与人类交流，呀呀学语的机器人首次说出实际的单词。
<br><br>
这一机器人技术的飞跃发展可能有助于新型机器人的研发，它能够以一种更自然、类人的方式说话，同时也能够揭示幼儿理解语言的奥秘。
<br><br>
幼儿在6个月大到14个月大之间，会从发出一些含糊不清的音节向能够说出真正的单词转变，这是完全掌握语言的必要步骤。某些“锚”一样的单词一旦被建立，它们就提供了通往词汇大门的线索，因此这时幼儿学说话也变得容易。
<br><br>
受到这种过程的启示，一支由英国赫特福德大学计算机科学家凯若琳?莱恩（Caroline Lyon）带领的团队向他们的iCub仿人机器人迪奇编入程序，程序中几乎包含了英语中所有的大约4000个音节。通过任意将音节组合在一起，迪奇可以像一个婴儿那样呀呀学语。
<br><br>
研究人员同时也招募了34个志愿者扮演老师的角色，他们被要求将迪奇当成是一个婴儿。迪奇和每位老师有8分钟的对话，在每段对话的间隙里，迪奇的记忆都被储存、擦除和重启，因此对于每位老师而言实验都是重新开始的。在每段对话开始时，迪奇词汇里每一个音节的分数都是完全相同的。
<br><br>
 

为词汇计分
<br><br>
课程开始后，一切都改变了。迪奇内部的程序设置是先听老师的讲话，然后再学着说，它把老师的讲话变成一个一个的音节，合计讲话中的音节个数。然后更新它的词汇分数，给每个曾经被老师用过的音节加分。当迪奇下一次讲话的时候，由于这些音节的得分高，因此更可能被迪奇重复。
<br><br>
莱恩说这让人联想起人类婴儿的学习方式，“当他们听到频繁出现的声音时，他们就会对这些声音变得敏感”，莱恩说，“他们更喜欢熟悉的声音”。
<br><br>
当迪奇说出可辨认的单词的时候，老师就会给予得分奖励，模仿学习通过这种方式得到提高。迪奇内部的程序会检测这些评论，并给予得到老师认可的音节额外的分数。当然不可避免的是，一些毫无意义的音节也会得到额外的得分。但是由于这种过程是不断重复的，只有那些可以组成单词的音节才能够持续不断地出现在获得认可的单词串中。
<br><br>
尽管迪奇依然会发出毫无意义的音节，但是在8分钟对话快结束的时候，实际单词持续出现的频率要比迪奇只是随机选择音节时的频率高。
<br><br>
在呀呀学语的时候，学习单词可以借助于一种基于统计的学习过程而不是具体的语法，这一事实证明了该阶段的语言学习并不需要强调语法能力，莱恩说到。
<br><br>
荷兰蒂尔堡大学的认知科学家保罗?沃格特对这一成果印象深刻，“对于开发能够帮助我们学习语言的机器人而言，这是非常有趣的第一步，”
<br><br>
目前，迪奇的说话能力离完全成熟的语言表达还很遥远，但是从呀呀学语开始可能是创造表达自然的机器人的最好方法。“如果你希望机器人能够表达得自然，那你可能需要从最初开始教它”，莱恩说到。
<br><br>
 

唯一重要的因素
<br><br>
并不是所有单词的组成都是相同的，当英国赫特福德大学凯若琳?莱恩的团队教给机器人一些基本的单词时，它更喜欢某些类型的单词，比如描述形状和色彩的单词包括“红色”、“绿色”、“心脏”、“方形”、“盒子”，它们比“这”或者“和”出现的更频繁。莱恩说，老师在进行教导的时候，“这”、 “和”出现得很频繁但是由于它们有时却一起被其他单词所遮盖，这使得机器人很难辨认它们。而一些显著的单词比如“红色”或者“绿色”，不管它们在句子的哪里出现，它们的发音都倾向于一致。莱恩的团队猜测，由于一些单词对于年龄较小的孩子而言有着更高的“信息价值”，或许正是这一区别帮助孩子们最先学习它们。

 <br><br>

（环球科学 张凡）
<br><br>


	<br><a href="#top">返回页首</a><br>
	


	<hr>
			
	<br><a href= "home.html">返回主页</a><br>

	</font>

	<hr>

	<center>
	<font size=3>
	version:1.0;&nbsp;jobnet@188.com&nbsp;&copy;&nbsp;<a href= "http://www.retter2012.com" title="点击进入">  retter2012.com </a> 
	</font>	
	</center>

</body>

</html>